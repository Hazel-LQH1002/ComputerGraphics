// filename: cw3_student.uclcg
// tabGroup: Coursework
// thumbnail: cw3_thumb.png
// displayname: Coursework 3 - 2022/2023
// shortDescription: Coursework 3 - Path Tracing
// author: None
// isHidden: false

function setup()
{
	UI = {};
	UI.tabs = [];
	UI.titleLong = 'Path Tracer';
	UI.titleShort = 'PathTracer';
	UI.numFrames = 10000;
	UI.maxFPS = 1000;
	UI.renderWidth = 1024;
	UI.renderHeight = 512;

	UI.tabs.push(
		{
		visible: true,
		type: `x-shader/x-fragment`,
		title: `Raytracing`,
		id: `TraceFS`,
		initialValue: `#define SOLUTION_LIGHT
#define SOLUTION_BOUNCE
#define SOLUTION_THROUGHPUT
#define SOLUTION_HALTON
#define SOLUTION_AA
#define SOLUTION_IS
#define SOLUTION_MB

precision highp float;

#define M_PI 3.1415


//In our case, gamma is used to make the image look better for our eyes, since the monitor will do the gamma correction itself which will lower the intensity
//and if we do not do the gamma correction in the code, the image will be dimmer and lose some details. With gamma correction in the code, we turn the space
//from the non-linear to the linear space, which all operations we are going to implement is supposed to be based on.
struct Material {
	#ifdef SOLUTION_LIGHT
	int light_source;
	#endif
	vec3 diffuse;
	vec3 specular;
	float glossiness;
};

struct Sphere {
	vec3 position;
#ifdef SOLUTION_MB
	vec3 motion_dir;
#endif
	float radius;
	Material material;
};

struct Plane {
	vec3 normal;
	float d;
	Material material;
};

const int sphereCount = 4;
const int planeCount = 4;
const int emittingSphereCount = 2;
#ifdef SOLUTION_BOUNCE
#define UNIT_TEST 0   //This is the simple flag for unit test 
               //if defines it to be 1, then starts running unit test
const int maxPathLength = 2;
#else
const int maxPathLength = 1;
#endif

struct Scene {
	Sphere[sphereCount] spheres;
	Plane[planeCount] planes;
};

struct Ray {
	vec3 origin;
	vec3 direction;
};

// Contains all information pertaining to a ray/object intersection
struct HitInfo {
	bool hit;
	float t;
	vec3 position;
	vec3 normal;
	Material material;
};

// Contains info to sample a direction and this directions probability
struct DirectionSample {
	vec3 direction;
	float probability;
};

HitInfo getEmptyHit() {
	Material emptyMaterial;
	#ifdef SOLUTION_LIGHT
	emptyMaterial.light_source = 0;
	#endif
	emptyMaterial.diffuse = vec3(0.0);
	emptyMaterial.specular = vec3(0.0);
	emptyMaterial.glossiness = 0.0;
	return HitInfo(false, 0.0, vec3(0.0), vec3(0.0), emptyMaterial);
}

// Sorts the two t values such that t1 is smaller than t2
void sortT(inout float t1, inout float t2) {
	// Make t1 the smaller t
	if(t2 < t1)  {
		float temp = t1;
		t1 = t2;
		t2 = temp;
	}
}

// Tests if t is in an interval
bool isTInInterval(const float t, const float tMin, const float tMax) {
	return t > tMin && t < tMax;
}

// Get the smallest t in an interval
bool getSmallestTInInterval(float t0, float t1, const float tMin, const float tMax, inout float smallestTInInterval) {

	sortT(t0, t1);

	// As t0 is smaller, test this first
	if(isTInInterval(t0, tMin, tMax)) {
		smallestTInInterval = t0;
		return true;
	}

	// If t0 was not in the interval, still t1 could be
	if(isTInInterval(t1, tMin, tMax)) {
		smallestTInInterval = t1;
		return true;
	}

	// None was
	return false;
}

// Converts a random integer in 15 bits to a float in (0, 1)
float randomInetegerToRandomFloat(int i) {
	return float(i) / 32768.0;
}

// Returns a random integer for every pixel and dimension that remains the same in all iterations
int pixelIntegerSeed(const int dimensionIndex) {
	vec3 p = vec3(gl_FragCoord.xy, dimensionIndex);
	vec3 r = vec3(23.14069263277926, 2.665144142690225,7.358926345 );
	return int(32768.0 * fract(cos(dot(p,r)) * 123456.0));
}

// Returns a random float for every pixel that remains the same in all iterations
float pixelSeed(const int dimensionIndex) {
	return randomInetegerToRandomFloat(pixelIntegerSeed(dimensionIndex));
}

// The global random seed of this iteration
// It will be set to a new random value in each step
uniform int globalSeed;
int randomSeed;
void initRandomSequence() {
	randomSeed = globalSeed + pixelIntegerSeed(0);
}

// Computes integer  x modulo y not available in most WEBGL SL implementations
int mod(const int x, const int y) {
	return int(float(x) - floor(float(x) / float(y)) * float(y));
}

// Returns the next integer in a pseudo-random sequence
int rand() {
	randomSeed = randomSeed * 1103515245 + 12345;
	return mod(randomSeed / 65536, 32768);
}

// Returns the next float in this pixels pseudo-random sequence
float uniformRandom() {
	return randomInetegerToRandomFloat(rand());
}

// Returns the ith prime number for the first 20
const int maxDimensionCount = 10;
int prime(const int index) {
	if(index == 0) return 2;
	if(index == 1) return 3;
	if(index == 2) return 5;
	if(index == 3) return 7;
	if(index == 4) return 11;
	if(index == 5) return 13;
	if(index == 6) return 17;
	if(index == 7) return 19;
	if(index == 8) return 23;
	if(index == 9) return 29;
	if(index == 10) return 31;
	if(index == 11) return 37;
	if(index == 12) return 41;
	if(index == 13) return 43;
	if(index == 14) return 47;
	if(index == 15) return 53;
	return 2;
}

#ifdef SOLUTION_HALTON
#endif

float halton(const int sampleIndex, const int dimensionIndex) {
	#ifdef SOLUTION_HALTON
	//To implement halton sampling, just calculate the Van der Corput with prime bases
  int base = prime(dimensionIndex); //get current prime base with help of prime table function
  float b = float(base);  
  float f = 1.0, r = 0.0;
   int index = sampleIndex;
  for(int i = 0; i < 200; i++){
    f = f/b;               //get the next index base i.e 0.1->0.001->0.0001
    r = r + f * float(mod(index,base));  //add it to the previous term
    index = index/base;        //prepare for the next iteration, clean the calculated part
	  if (index <= 0) break;
  }
  //return r;
	// if directly uncomment the above line 'return r',you will get structural patterns. To avoid this
	// pattern, we use Cranely-Petterson rotation, which means to do a random shift first, and if the random 
	// shift is beyond [0,1) then modulate it back to [0,1)
	//To implement it, we have two options to get the random shift: use function pixelSeed or uniformRandom;
	//I tried both methods and compared the speed. The result proves that pixelSeed converges faster than uniformRandom
	//and both functions have already ensured the random shift is in [0.1), so I just directly added the pixelSeed to the result;
	return fract(r + pixelSeed(dimensionIndex));
	#else
	// Put your implementation of halton in the #ifdef above 
	return 0.0;
	#endif
}

// This is the index of the sample controlled by the framework.
// It increments by one in every call of this shader
uniform int baseSampleIndex;

// Returns a well-distributed number in (0,1) for the dimension dimensionIndex
float sample(const int dimensionIndex) {
	#ifdef SOLUTION_HALTON
	return halton(baseSampleIndex,dimensionIndex);
	#else
	// Use the Halton sequence for variance reduction in the #ifdef above
	return uniformRandom();
	#endif
}
// This is a helper function to sample two-dimensionaly in dimension dimensionIndex
vec2 sample2(const int dimensionIndex) {
	return vec2(sample(dimensionIndex + 0), sample(dimensionIndex + 1));
}

vec3 sample3(const int dimensionIndex) {
	return vec3(sample(dimensionIndex + 0), sample(dimensionIndex + 1), sample(dimensionIndex + 2));
}

// This is a register of all dimensions that we will want to sample.
// Thanks to Iliyan Georgiev from Solid Angle for explaining proper housekeeping of sample dimensions in ranomdized Quasi-Monte Carlo
//
// So if we want to use lens sampling, we call sample(LENS_SAMPLE_DIMENSION).
//
// There are infinitely many path sampling dimensions.
// These start at PATH_SAMPLE_DIMENSION.
// The 2D sample pair for vertex i is at PATH_SAMPLE_DIMENSION + PATH_SAMPLE_DIMENSION_MULTIPLIER * i + 0
#define ANTI_ALIAS_SAMPLE_DIMENSION 0
#define TIME_SAMPLE_DIMENSION 1
#define PATH_SAMPLE_DIMENSION 3

// This is 2 for two dimensions and 2 as we use it for two purposese: NEE and path connection
#define PATH_SAMPLE_DIMENSION_MULTIPLIER (2 * 2)

vec3 getEmission(const Material material, const vec3 normal) {
	#ifdef SOLUTION_LIGHT
	if (material.light_source == 1){
		return 150.0*vec3(0.9, 0.9, 0.5);
	}else if (material.light_source == 2){
		return 150.0*vec3(0.8, 0.3, 0.1);
	}
	#else
	// This is wrong. It just returns the diffuse color so that you see something to be sure it is working.
	return material.diffuse;
	#endif
}

//This function is used to calculate BRDF in the rendering equation
//According to physically-correct Phong fomulation, BRDF equals to:
//kd/PI + ks*((n+2)/(2*PI)*(<w0,r>^+)^n
//To implement this equation, I split it into four parts: 1)kd/PI, 2)ks, 3)(n+2)/(2*PI) (name it as cof) and 4)(<w0,r>^+)^n (name it as angle)
vec3 getReflectance(const Material material, const vec3 normal, const vec3 inDirection, const vec3 outDirection) {
	#ifdef SOLUTION_THROUGHPUT
	//get the diffusion coefficient, kd, from material struture
	vec3 kd = material.diffuse;
	//get the specular coefficient, ks, from material struture
	vec3 ks = material.specular;
	float n = material.glossiness;
	//Get the third term, coefficient term
	float cof = (n + 2.0)/(2.0*M_PI);
	vec3 N = normal;
	
	//r is the ideal reflection direction of the incoming ray when the material is a perfect mirror
	//To calculate the reflection direction, I use the equation I - 2<I,N>N
	vec3 r = normalize(normalize(inDirection) - 2.0*dot(normalize(inDirection),N)*N);
	//After getting r, the last term can be calculated. Here I use max(x,0) to get the positive part
	float angle = max((dot(normalize(outDirection),r)),0.0);
	//makes the last term power of n
	angle = pow(angle,n);
	//add four terms together
	return kd/M_PI + ks*cof*angle;
	#else
	return vec3(1.0);
	#endif
}


//The geometric term is the cos(theta) term in the rendering equation, therefore we only need to calculate 
//the cosine value of the angle between normal and outcoming ray. Since the dot product of two normalized vectors 
//exactly equals to the cosine value, so I directly return the dot product of normal and normalized outcoming ray

vec3 getGeometricTerm(const Material material, const vec3 normal, const vec3 inDirection, const vec3 outDirection) {
	#ifdef SOLUTION_THROUGHPUT
	vec3 N = normal;
	float result = dot(N,normalize(outDirection));
	return vec3(result,result,result);
	#else
	return vec3(1.0);
	#endif
}

vec3 sphericalToEuclidean(float theta, float phi) {
	float x = sin(theta) * cos(phi);
	float y = sin(theta) * sin(phi);
	float z = cos(theta);
	return vec3(x, y, z);	
}

vec3 getRandomDirection(const int dimensionIndex) {
	#ifdef SOLUTION_BOUNCE
	vec2 samples = sample2(dimensionIndex);
	float theta = acos(2.0 * samples.x - 1.0);
	float phi = samples.y*2.0*M_PI;
	return sphericalToEuclidean(theta,phi);
	#else
	// Put your code to compute a random direction in 3D in the #ifdef above
	return vec3(0);
	#endif
}


HitInfo intersectSphere(const Ray ray, Sphere sphere, const float tMin, const float tMax) {

#ifdef SOLUTION_MB
	sphere.position = sphere.position + (sphere.motion_dir)*pixelSeed(baseSampleIndex);
#endif
	
	vec3 to_sphere = ray.origin - sphere.position;

	float a = dot(ray.direction, ray.direction);
	float b = 2.0 * dot(ray.direction, to_sphere);
	float c = dot(to_sphere, to_sphere) - sphere.radius * sphere.radius;
	float D = b * b - 4.0 * a * c;
	if (D > 0.0)
	{
		float t0 = (-b - sqrt(D)) / (2.0 * a);
		float t1 = (-b + sqrt(D)) / (2.0 * a);

		float smallestTInInterval;
		if(!getSmallestTInInterval(t0, t1, tMin, tMax, smallestTInInterval)) {
			return getEmptyHit();
		}

		vec3 hitPosition = ray.origin + smallestTInInterval * ray.direction;

		vec3 normal =
			length(ray.origin - sphere.position) < sphere.radius + 0.001?
			-normalize(hitPosition - sphere.position) :
		normalize(hitPosition - sphere.position);

		return HitInfo(
			true,
			smallestTInInterval,
			hitPosition,
			normal,
			sphere.material);
	}
	return getEmptyHit();
}

HitInfo intersectPlane(Ray ray, Plane plane) {
	float t = -(dot(ray.origin, plane.normal) + plane.d) / dot(ray.direction, plane.normal);
	vec3 hitPosition = ray.origin + t * ray.direction;
	return HitInfo(
		true,
		t,
		hitPosition,
		normalize(plane.normal),
		plane.material);
	return getEmptyHit();
}

float lengthSquared(const vec3 x) {
	return dot(x, x);
}

HitInfo intersectScene(Scene scene, Ray ray, const float tMin, const float tMax)
{
	HitInfo best_hit_info;
	best_hit_info.t = tMax;
	best_hit_info.hit = false;

	for (int i = 0; i < sphereCount; ++i) {
		Sphere sphere = scene.spheres[i];
		HitInfo hit_info = intersectSphere(ray, sphere, tMin, tMax);

		if(	hit_info.hit &&
		   hit_info.t < best_hit_info.t &&
		   hit_info.t > tMin)
		{
			best_hit_info = hit_info;
		}
	}

	for (int i = 0; i < planeCount; ++i) {
		Plane plane = scene.planes[i];
		HitInfo hit_info = intersectPlane(ray, plane);

		if(	hit_info.hit &&
		   hit_info.t < best_hit_info.t &&
		   hit_info.t > tMin)
		{
			best_hit_info = hit_info;
		}
	}

	return best_hit_info;
}

mat3 transpose(mat3 m) {
	return mat3(
		m[0][0], m[1][0], m[2][0],
		m[0][1], m[1][1], m[2][1],
		m[0][2], m[1][2], m[2][2]
	);
}

// This function creates a matrix to transform from global space into a local space oriented around the normal.
// Might be useful for importance sampling BRDF / the geometric term.
mat3 makeLocalFrame(const vec3 normal) {
	#ifdef SOLUTION_IS
	vec3 world_x = vec3(1.0, 0, 0);
	vec3 world_y = vec3(0, 1.0, 0);
	vec3 world_z = vec3(0, 0, 1.0);
	//the next step is to find a vector which is orthogonal to the normal and make it as local y
	//here I directly assume normal as the local_z
	vec3 local_z = normalize(normal);
	vec3 local_y = normalize(cross(normal,vec3(1,0,0)));
	if (abs(normal.x) > abs(normal.y)) local_y = normalize(cross(normal,vec3(0,0,1)));
	//local x is the vector orthogonal to both local_z and local_y, so by taking the cross product of local_y and local_z, we can get local_x
	vec3 local_x = cross(local_z, local_y);
   //to calculate the transformation matrix, we only need to calculate the angle i.e the cosine value
	//since all vectors are normalized, only need to take the dot products
	return mat3(dot(local_x, world_x), dot(local_x, world_y), dot(local_x, world_z),
				dot(local_y, world_x), dot(local_y, world_y), dot(local_y, world_z),
				dot(local_z, world_x), dot(local_z, world_y), dot(local_z, world_z));
	


	#else
	return mat3(1.0);
	#endif
}

//Question 1:
//Basically,the most basic job I expect such an importance sampling to do is to give differnt weights
//to different samples instead of give them equal weights. And the weight should be determined by
//the angle between the sample direction and the normal. Less contribution from vectors far 
//away from the normal and more contribution from vectors close to the normal.In conclusion, IS is used to relatively get rid of
//randomness and makes every sampling more meaningful
//Question 2:
//I ran for 10000 samples with and without importance sampling. I found that with importance sampling,
//there are less noises and if focus on the light shadow on the wall, the difference is more obvious. 
// Without IS, there are more noises on the shadow, some pixels are brighter and some are dimmer. But 
//with IS, the color of pixels in the shadow are more similar with each other, which makes the shadow seem to be more smooth.

DirectionSample sampleDirection(const vec3 normal, const int dimensionIndex) {
	DirectionSample result;

	#ifdef SOLUTION_IS
	mat3 transformation_mat = makeLocalFrame(normal);
	vec3 sum_direction = vec3(0.0);
	float sum_cos = 0.0;
		vec2 s = sample2(dimensionIndex);
     float theta = acos(sqrt(1.0-s.x));
	  float phi = s.y*2.0*M_PI;
	  vec3 random_direction = normalize(sphericalToEuclidean(theta,phi)); 
	result.direction = random_direction * transpose(transformation_mat);
	result.probability = 4.0*cos(s.x);

	
	// transform to world coordinate and calculate the average probability and direction 

	
	#else
	// Put yout code to compute Importance Sampling in the #ifdef above 
	result.direction = getRandomDirection(dimensionIndex);	
	result.probability = 1.0;
	#endif
	return result;
}


vec3 samplePath(const Scene scene, const Ray initialRay) {

	// Initial result is black
	vec3 result = vec3(0);

	Ray incomingRay = initialRay;
	vec3 throughput = vec3(1.0);
	for(int i = 0; i < maxPathLength; i++) {
		HitInfo hitInfo = intersectScene(scene, incomingRay, 0.001, 10000.0);

		if(!hitInfo.hit) return result;


		result += throughput * getEmission(hitInfo.material, hitInfo.normal);

		Ray outgoingRay;
		DirectionSample directionSample;
		#ifdef SOLUTION_BOUNCE
		directionSample = sampleDirection(hitInfo.normal,PATH_SAMPLE_DIMENSION+2*i);
		outgoingRay.origin = hitInfo.position;
		outgoingRay.direction = directionSample.direction;
		//This is for unit test, the unit test is supposed to be the test on the "randomness" of the RNG generator
	   //and in my designed unit test, the randomness will be shown as color which is easier to observe
		//The test can be run by setting the UNIT_TEST flag to 1. The third function involved is the sampleDirection
		//function. Since we need to test whether it generates 'correct' random direction,
		//therfore I directly return the result as color which is easy to check.
		//You can start running unit_test together with IS, which will have a better view effect.
		if (UNIT_TEST == 1) {
			return directionSample.direction;
		}
		#else
		// Put your code to compute the next ray in the #ifdef above
		#endif

		//According to rendering equation, BRDF and geometric terms should be multiplied together and the whole is named as "throughput", 
		//i.e. BRDF*L*Geometric = (BRDF*Geometric)*L = throughput*L. I only need to multiply the BRDF and geometric terms with previous 
		//throughput and get updated throughput.
     //The reason I multiply the BRDF and geometric terms with previous throughput is for every reflection, 
		//we want to know the current throughput * current ray
		//which equals to current throughput * (previous throughput * emission) = (current throughput * previous throughput) * emission
		#ifdef SOLUTION_THROUGHPUT
		 vec3 R = getReflectance(hitInfo.material, hitInfo.normal,incomingRay.direction,outgoingRay.direction);
      vec3 G = getGeometricTerm(hitInfo.material, hitInfo.normal,incomingRay.direction,outgoingRay.direction);
		 throughput *= R*G;
		#else
		// Compute the proper throughput in the #ifdef above 
		throughput *= 0.1;
		#endif

		#ifdef SOLUTION_IS
     throughput /= directionSample.probability;
		#else
		// Without Importance Sampling, there is nothing to do here. 
		// Put your Importance Sampling code in the #ifdef above
		#endif

		#ifdef SOLUTION_BOUNCE
		incomingRay = outgoingRay;
		#else
		// Put some handling of the next and the current ray in the #ifdef above
		#endif
	}
	return result;
}

uniform ivec2 resolution;
Ray getFragCoordRay(const vec2 fragCoord) {

	float sensorDistance = 1.0;
	vec3 origin = vec3(0, 0, sensorDistance);
	vec2 sensorMin = vec2(-1, -0.5);
	vec2 sensorMax = vec2(1, 0.5);
	vec2 pixelSize = (sensorMax - sensorMin) / vec2(resolution);
	vec3 direction = normalize(vec3(sensorMin + pixelSize * fragCoord, -sensorDistance));

	float apertureSize = 0.0;
	float focalPlane = 100.0;
	vec3 sensorPosition = origin + focalPlane * direction;
	origin.xy += -vec2(0.5);
	direction = normalize(sensorPosition - origin);

	return Ray(origin, direction);
}

vec3 colorForFragment(const Scene scene, const vec2 fragCoord) {
	initRandomSequence();

	#ifdef SOLUTION_AA
	//Aliasing happens because every time, the ray shoots at the center of every pixel.
	//Therefore, the main idea to do the antialiasing is to disperse samples instead of
	//gathering at the center. Thus, I add a random shift for the sample and in order to 
	//ensure the sample is within the pixel, 0.5 is reducted from x,y respectively.
	vec2 sampleCoord = fragCoord + vec2(uniformRandom()-0.5,uniformRandom()-0.5);
	#else  	
	// Put your anti-aliasing code in the #ifdef above
	vec2 sampleCoord = fragCoord;
	#endif
	return samplePath(scene, getFragCoordRay(sampleCoord));
}


void loadScene1(inout Scene scene) {

	scene.spheres[0].position = vec3( 7, -2, -12);
	scene.spheres[0].radius = 2.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[0].material.light_source = 1;
#endif
	scene.spheres[0].material.diffuse = vec3(0.0);
	scene.spheres[0].material.specular = vec3(0.0);
	scene.spheres[0].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[0].motion_dir = vec3(0.0,0.0,0.0);
#endif
	
	scene.spheres[1].position = vec3(-8, 4, -13);
	scene.spheres[1].radius = 1.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[1].material.light_source = 2;
#endif
	scene.spheres[1].material.diffuse = vec3(0.0);
	scene.spheres[1].material.specular = vec3(0.0);
	scene.spheres[1].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[1].motion_dir = vec3(0.0,0.0,0.0);
#endif
	
	scene.spheres[2].position = vec3(-2, -2, -12);
	scene.spheres[2].radius = 3.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[2].material.light_source = 3;
#endif  
	scene.spheres[2].material.diffuse = vec3(0.2, 0.5, 0.8);
	scene.spheres[2].material.specular = vec3(0.8);
	scene.spheres[2].material.glossiness = 40.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[2].motion_dir = vec3(-3.0,0.0,3.0);
#endif
	
	scene.spheres[3].position = vec3(3, -3.5, -14);
	scene.spheres[3].radius = 1.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[3].material.light_source = 4;
#endif  
	scene.spheres[3].material.diffuse = vec3(0.9, 0.8, 0.8);
	scene.spheres[3].material.specular = vec3(1.0);
	scene.spheres[3].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[3].motion_dir = vec3(2.0,4.0,1.0);
	//scene.spheres[3].time++;
#endif
	
	scene.planes[0].normal = vec3(0, 1, 0);
	scene.planes[0].d = 4.5;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT   
	scene.planes[0].material.light_source = 0;
#endif
	scene.planes[0].material.diffuse = vec3(0.8);
	scene.planes[0].material.specular = vec3(0);
	scene.planes[0].material.glossiness = 50.0;    

	scene.planes[1].normal = vec3(0, 0, 1);
	scene.planes[1].d = 18.5;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[1].material.light_source = 0;
#endif
	scene.planes[1].material.diffuse = vec3(0.9, 0.6, 0.3);
	scene.planes[1].material.specular = vec3(0.02);
	scene.planes[1].material.glossiness = 3000.0;

	scene.planes[2].normal = vec3(1, 0,0);
	scene.planes[2].d = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[2].material.light_source = 0;
#endif
	
	scene.planes[2].material.diffuse = vec3(0.2);
	scene.planes[2].material.specular = vec3(0.1);
	scene.planes[2].material.glossiness = 100.0; 

	scene.planes[3].normal = vec3(-1, 0,0);
	scene.planes[3].d = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[3].material.light_source = 0;
#endif
	
	scene.planes[3].material.diffuse = vec3(0.2);
	scene.planes[3].material.specular = vec3(0.1);
	scene.planes[3].material.glossiness = 100.0; 
}


void main() {
	// Setup scene
	Scene scene;
	loadScene1(scene);

	// compute color for fragment
	gl_FragColor.rgb = colorForFragment(scene, gl_FragCoord.xy);
	gl_FragColor.a = 1.0;
}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	UI.tabs.push(
		{
		visible: true,
		type: `x-shader/x-fragment`,
		title: `Tonemapping`,
		id: `CopyFS`,
		initialValue: `precision highp float;

uniform sampler2D radianceTexture;
uniform int sampleCount;
uniform ivec2 resolution;

vec3 tonemap(vec3 color, float maxLuminance, float gamma) {
	float luminance = length(color);
	//float scale =  luminance /  maxLuminance;
	float scale =  luminance / (maxLuminance * luminance + 0.0000001);
  	return max(vec3(0.0), pow(scale * color, vec3(1.0 / gamma)));
}

void main(void) {
  vec3 texel = texture2D(radianceTexture, gl_FragCoord.xy / vec2(resolution)).rgb;
  vec3 radiance = texel / float(sampleCount);
  gl_FragColor.rgb = tonemap(radiance, 1.0, 1.6);
  gl_FragColor.a = 1.0;
}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	UI.tabs.push(
		{
		visible: false,
		type: `x-shader/x-vertex`,
		title: ``,
		id: `VS`,
		initialValue: `
	attribute vec3 position;
	void main(void) {
		gl_Position = vec4(position, 1.0);
	}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	 return UI; 
}//!setup


function getShader(gl, id) {

		gl.getExtension('OES_texture_float');
		//alert(gl.getSupportedExtensions());

	var shaderScript = document.getElementById(id);
	if (!shaderScript) {
		return null;
	}

	var str = "";
	var k = shaderScript.firstChild;
	while (k) {
		if (k.nodeType == 3) {
			str += k.textContent;
		}
		k = k.nextSibling;
	}

	var shader;
	if (shaderScript.type == "x-shader/x-fragment") {
		shader = gl.createShader(gl.FRAGMENT_SHADER);
	} else if (shaderScript.type == "x-shader/x-vertex") {
		shader = gl.createShader(gl.VERTEX_SHADER);
	} else {
		return null;
	}

    console.log(str);
	gl.shaderSource(shader, str);
	gl.compileShader(shader);

	if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
		alert(gl.getShaderInfoLog(shader));
		return null;
	}

	return shader;
}

function RaytracingDemo() {
}

function initShaders() {

	traceProgram = gl.createProgram();
	gl.attachShader(traceProgram, getShader(gl, "VS"));
	gl.attachShader(traceProgram, getShader(gl, "TraceFS"));
	gl.linkProgram(traceProgram);
	gl.useProgram(traceProgram);
	traceProgram.vertexPositionAttribute = gl.getAttribLocation(traceProgram, "position");
	gl.enableVertexAttribArray(traceProgram.vertexPositionAttribute);

	copyProgram = gl.createProgram();
	gl.attachShader(copyProgram, getShader(gl, "VS"));
	gl.attachShader(copyProgram, getShader(gl, "CopyFS"));
	gl.linkProgram(copyProgram);
	gl.useProgram(copyProgram);
	traceProgram.vertexPositionAttribute = gl.getAttribLocation(copyProgram, "position");
	gl.enableVertexAttribArray(copyProgram.vertexPositionAttribute);

}

function initBuffers() {
	triangleVertexPositionBuffer = gl.createBuffer();
	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);

	var vertices = [
		 -1,  -1,  0,
		 -1,  1,  0,
		 1,  1,  0,

		 -1,  -1,  0,
		 1,  -1,  0,
		 1,  1,  0,
	 ];
	gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW);
	triangleVertexPositionBuffer.itemSize = 3;
	triangleVertexPositionBuffer.numItems = 3 * 2;
}


function tick() {

// 1st pass: Trace
	gl.bindFramebuffer(gl.FRAMEBUFFER, rttFramebuffer);

	gl.useProgram(traceProgram);
  	gl.uniform1i(gl.getUniformLocation(traceProgram, "globalSeed"), Math.random() * 32768.0);
	gl.uniform1i(gl.getUniformLocation(traceProgram, "baseSampleIndex"), getCurrentFrame());
	gl.uniform2i(
		gl.getUniformLocation(traceProgram, "resolution"),
		getRenderTargetWidth(),
		getRenderTargetHeight());

	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);
	gl.vertexAttribPointer(
		traceProgram.vertexPositionAttribute,
		triangleVertexPositionBuffer.itemSize,
		gl.FLOAT,
		false,
		0,
		0);

    	gl.viewport(0, 0, gl.viewportWidth, gl.viewportHeight);

	gl.disable(gl.DEPTH_TEST);
	gl.enable(gl.BLEND);
	gl.blendFunc(gl.ONE, gl.ONE);

	gl.drawArrays(gl.TRIANGLES, 0, triangleVertexPositionBuffer.numItems);

// 2nd pass: Average
   	gl.bindFramebuffer(gl.FRAMEBUFFER, null);

	gl.useProgram(copyProgram);
	gl.uniform1i(gl.getUniformLocation(copyProgram, "sampleCount"), getCurrentFrame() + 1);

	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);
	gl.vertexAttribPointer(
		copyProgram.vertexPositionAttribute,
		triangleVertexPositionBuffer.itemSize,
		gl.FLOAT,
		false,
		0,
		0);

    	gl.viewport(0, 0, gl.viewportWidth, gl.viewportHeight);

	gl.disable(gl.DEPTH_TEST);
	gl.disable(gl.BLEND);

	gl.activeTexture(gl.TEXTURE0);
    	gl.bindTexture(gl.TEXTURE_2D, rttTexture);
	gl.uniform1i(gl.getUniformLocation(copyProgram, "radianceTexture"), 0);
	gl.uniform2i(
		gl.getUniformLocation(copyProgram, "resolution"),
		getRenderTargetWidth(),
		getRenderTargetHeight());

	gl.drawArrays(gl.TRIANGLES, 0, triangleVertexPositionBuffer.numItems);

	gl.bindTexture(gl.TEXTURE_2D, null);
}

function init() {
	initShaders();
	initBuffers();
	gl.clear(gl.COLOR_BUFFER_BIT);

	rttFramebuffer = gl.createFramebuffer();
	gl.bindFramebuffer(gl.FRAMEBUFFER, rttFramebuffer);

	rttTexture = gl.createTexture();
	gl.bindTexture(gl.TEXTURE_2D, rttTexture);
    	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);

	gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, getRenderTargetWidth(), getRenderTargetHeight(), 0, gl.RGBA, gl.FLOAT, null);

	gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, rttTexture, 0);
}

var oldWidth = 0;
var oldTraceProgram;
var oldCopyProgram;
function compute(canvas) {

	if(	getRenderTargetWidth() != oldWidth ||
		oldTraceProgram != document.getElementById("TraceFS") ||
		oldCopyProgram !=  document.getElementById("CopyFS"))
	{
		init();

		oldWidth = getRenderTargetWidth();
		oldTraceProgram = document.getElementById("TraceFS");
		oldCopyProgram = document.getElementById("CopyFS");
	}

	tick();
}
